{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118686cf",
   "metadata": {},
   "source": [
    "# Creation dataframe of keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f9eb3c",
   "metadata": {},
   "source": [
    "_Foreword_\n",
    "\n",
    "The goal of this notebook is to create a pandas dataframe, containing for each paper, the keywords extracted from the title and the abstract of the paper using keybert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df29c3c",
   "metadata": {},
   "source": [
    "Importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580cbee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from myfunctions import get_dico_keywords, get_keyword,clean_text\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fbe9fe",
   "metadata": {},
   "source": [
    "Importing df_full_cleaned, that was cleaned and processed by the file \"dataexploration_full_data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bae8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_data_full = open('../exploratory_analysis/data_exploratory_analysis/df_full_cleaned','rb')\n",
    "df_full = pickle.load(infile_data_full)\n",
    "infile_data_full.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6162d4",
   "metadata": {},
   "source": [
    "We define some variables and the dictionary in which we will put all the information about the keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7bfb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myyears = [2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022]\n",
    "mymonths = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\\\n",
    "           'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f888a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ['paper','keyword','cosine_similarity','publication_date','year','month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08d45993",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicokeywords = {'paper':[],\n",
    "                'keyword':[],\n",
    "                'cosine_similarity':[],\n",
    "                'publication_date':[],\n",
    "                'year':[],\n",
    "                'month':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a34820d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full[['paper','title','publication_date','year','month','abstract']]\n",
    "df_full = df_full.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e959a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "listpaper_first = list(set(df_full.paper.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2220fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fractioning_number = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258345a5",
   "metadata": {},
   "source": [
    "I extract all the keywords from all my papers and save them as lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a295d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [1:28:19<00:00, 53.00s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [1:23:40<00:00, 50.20s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [1:20:05<00:00, 48.06s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [1:19:12<00:00, 47.53s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [1:18:19<00:00, 46.99s/it]\n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    list_listkeywords = []\n",
    "    list_listcosim = []\n",
    "    \n",
    "    #I first split the dataset in 5 subsets\n",
    "    step = int(math.floor(len(listpaper_first)/ 5))\n",
    "    start = j * step\n",
    "    if j == 4:\n",
    "        end = len(listpaper_first)\n",
    "    else:\n",
    "        end = (j + 1) * step\n",
    "    listpaper = listpaper_first[start:end]\n",
    "    \n",
    "    #Then I split these subsets in even smaller subsets\n",
    "    for i in tqdm(range(fractioning_number)):\n",
    "        step = int(math.floor(len(listpaper) / fractioning_number))\n",
    "        start = i*step\n",
    "        end = (i+1)*step\n",
    "        if i == fractioning_number-1:\n",
    "            end = len(listpaper)\n",
    "        restricted_listpaper=listpaper[start:end]\n",
    "        \n",
    "        #I choose only rows of my pandas dataframe of the paper I am analyzing\n",
    "        mypapers =df_full[df_full['paper'].isin(restricted_listpaper)].copy()\n",
    "        \n",
    "        #I now extract the keywords\n",
    "        for paper in restricted_listpaper:\n",
    "            myinfos = mypapers.loc[mypapers['paper']==paper].copy()\n",
    "            abstract = list(set(myinfos.abstract.tolist()))\n",
    "            title = list(set(myinfos.title.tolist()))\n",
    "            text = str(title[0] + abstract[0])\n",
    "\n",
    "            text_c = clean_text(text)\n",
    "\n",
    "            # this functions get_keyword take 99.99% of the running time for each loop\n",
    "            mykeywords = get_keyword(text_c)\n",
    "\n",
    "            numberkeywords = len(mykeywords)\n",
    "\n",
    "            # actually mykeywords is a list of tuples (with the keyword and its cosine similarity which is a measure of \n",
    "            # the closeness of the keyword to the text)\n",
    "            # I take every element of the list and then I take the\n",
    "            # elements of the tuple I am interested in.\n",
    "            listkeywords = []\n",
    "            listcosim=[]\n",
    "            for y in range(numberkeywords):\n",
    "                infomykey = mykeywords[y]\n",
    "                listkeywords.append(infomykey[0])\n",
    "                listcosim.append(infomykey[1])\n",
    "            list_listkeywords.append(listkeywords)\n",
    "            list_listcosim.append(listcosim)\n",
    "    \n",
    "    # saving my list of keywords and cosine similarity\n",
    "    with open(\"data_creation_variables/list_listkeywords\"+str(j), \"wb\") as fp:  # Pickling\n",
    "        pickle.dump(list_listkeywords, fp)\n",
    "    with open(\"data_creation_variables/list_listcosim\"+str(j), \"wb\") as fp:  # Pickling\n",
    "        pickle.dump(list_listcosim, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcc733aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now generate a list of keywords and cosine similarity out of all the lists which were created \n",
    "list_keywords = []\n",
    "list_cosim = []\n",
    "for j in range(5):\n",
    "    with open(\"data_creation_variables/list_listkeywords\"+str(j), 'rb') as f:\n",
    "        list_keywords=list_keywords+pickle.load(f)\n",
    "    with open(\"data_creation_variables/list_listcosim\"+str(j), 'rb') as f:\n",
    "        list_cosim = list_cosim + pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21962ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full[['paper','publication_date','year','month']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c861fc",
   "metadata": {},
   "source": [
    "We define some functions that we will use to construct our pandas dataframe of keywords. It's quite clear what they do, they just take the publication date, year and month of each given paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361783b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_publication_date(paper,df_full):\n",
    "    df = df_full.loc[df_full['paper']==paper].copy()\n",
    "    listinfo = df.publication_date.tolist()\n",
    "    return listinfo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae7d0e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(paper,df_full):\n",
    "    df = df_full.loc[df_full['paper']==paper].copy()\n",
    "    listinfo = df.year.tolist()\n",
    "    return listinfo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e461530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month(paper,df_full):\n",
    "    df = df_full.loc[df_full['paper']==paper].copy()\n",
    "    listinfo = df.month.tolist()\n",
    "    return listinfo[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d67edf6",
   "metadata": {},
   "source": [
    "I create the list of information and so on and I just create the pandas dataframe out of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "416d8658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 131120/131120 [15:11<00:00, 143.80it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 131120/131120 [14:36<00:00, 149.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 131120/131120 [14:33<00:00, 150.10it/s]\n"
     ]
    }
   ],
   "source": [
    "publication_list = list(map(lambda x: get_publication_date(x, df_full), tqdm(listpaper_first)))\n",
    "month_list = list(map(lambda x: get_month(x, df_full), tqdm(listpaper_first)))\n",
    "year_list = list(map(lambda x: get_year(x, df_full), tqdm(listpaper_first)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9e3476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicokeywords['keyword']=list_keywords\n",
    "dicokeywords['cosine_similarity']= list_cosim\n",
    "dicokeywords['paper']=listpaper_first\n",
    "dicokeywords['publication_date']=publication_list\n",
    "dicokeywords['year']=year_list\n",
    "dicokeywords['month']=month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c084e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkeywords = pd.DataFrame(dicokeywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b1a7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last but not least I explode the rows containing the keywords and \n",
    "#cosine similarity since there were lists of keywords and cosine similarity in these cells\n",
    "dfkeywords =dfkeywords.explode(['keyword', 'cosine_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec847240",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkeywords.to_pickle('data_creation_variables/dfkeywords')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
